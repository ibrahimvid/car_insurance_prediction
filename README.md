# Car Insurance Purchase Prediction

End‑to‑end machine learning project that predicts which customers are likely to purchase a car insurance product, using demographic, financial, and campaign contact features.

The goal is to help a marketing/sales team prioritize outbound calls and focus effort on high‑propensity customers.

## Table of Contents
- [Problem Statement](#problem-statement)
- [Business Context](#business-context)
- [Dataset](#dataset)
- [Modeling Approach](#modeling-approach)
- [Evaluation & Key Metrics](#evaluation--key-metrics)
- [Insights & Business Impact](#insights--business-impact)
- [Installation](#installation)
- [Usage](#usage)
- [Notebooks](#notebooks)
- [Results](#results)
- [Technologies](#technologies)
- [Directory Structure](#directory-structure)
- [Contributing](#contributing)
- [License](#license)

## Problem Statement

Given historical telemarketing campaign data, predict whether a contacted customer will purchase a car insurance policy (`car_insurance` = 1) or not (`car_insurance` = 0).

Formally, this is a binary classification problem where each row represents a customer contact and the model outputs the probability of purchase.

## Business Context

Calling every lead is expensive and hurts customer experience. By ranking customers by predicted purchase probability, a sales team can:
- Prioritize high‑propensity customers for outbound calls.
- Reduce time spent on low‑conversion leads.
- Design targeted campaigns for specific customer segments (e.g., age, income, job type).

This project mimics a real‑world marketing analytics use case where a data scientist delivers a model that directly supports campaign strategy and resource allocation.

## Dataset

The dataset consists of telemarketing campaign records with customer demographics, financials, and contact history.

Files:
- `data/Train_data.csv`: Training set with target variable `car_insurance`.
- `data/Test_data.csv`: Test set without the target.
- `Sample_Submission.csv`: Example submission format.
- `prediction_results.csv`: Predictions generated by the best model.

Example features include:
- Demographics: `age`, `job_type`, `marital_status`, `education_level`
- Financial: `balance_amt`, `household_insurance`, `car_loan`, `default_or_not`
- Contact & campaign: `communication`, `last_contact_day`, `last_contact_month`, `no_of_contacts`, `days_passed`, `prev_attempts`, `Outcome`, `call_start`, `call_end`
- Target: `car_insurance` (0 = not purchased, 1 = purchased)

Missing values and categorical variables are handled during preprocessing in the notebooks.

## Modeling Approach

The project follows a standard supervised learning workflow:
- **Exploratory Data Analysis (EDA)**  
  Understand class balance, feature distributions, and relationships (e.g., purchase rates by age group, job type, and previous campaign outcome).
- **Data Cleaning**  
  Handle missing values, inconsistent categories, and outliers where relevant.
- **Feature Engineering**  
  - Encode categorical variables (e.g., one‑hot encoding for `job_type`, `education_level`, `Outcome`).  
  - Derive time‑based and campaign features (e.g., number of previous contacts, recency of last contact).
- **Train/Test Split**  
  Split the training data into train/validation sets to evaluate different models.
- **Model Selection & Training**  
  Train multiple classifiers, including:
  - Logistic Regression  
  - Random Forest  
  - Gradient Boosting / XGBoost  
- **Hyperparameter Tuning**  
  Use `GridSearchCV` and `RandomizedSearchCV` (see `Car_Insurance.ipynb`) to tune key parameters for tree‑based models.
- **Evaluation & Model Comparison**  
  Compare models on held‑out data using classification metrics, then select a final model to generate `prediction_results.csv` for the test set.

This structure demonstrates an end‑to‑end DS workflow: from raw CSVs to a tuned model and deployable predictions file.

## Evaluation & Key Metrics

This is a classification problem, so the primary metric is **accuracy** on a held‑out test set. The notebooks also import other metrics (`precision`, `recall`, `f1_score`) and can be extended to emphasize those if the business cares more about correctly identifying buyers (recall) vs. avoiding false positives (precision).

From the experiments in `Car_Insurance.ipynb`:
- A simple baseline model (e.g., untuned Logistic Regression) achieves accuracy around **0.77–0.83**.
- Tuned tree‑based models improve test accuracy to approximately **0.87**, depending on the hyperparameters.

This demonstrates a clear lift from baseline to the best model, which is important to highlight on a resume:
- **Baseline:** ~0.8 accuracy  
- **Best tuned model:** ~0.87 accuracy on the test split  

You can further extend the evaluation to include:
- **ROC‑AUC** for ranking quality.
- **Precision/Recall/F1** to capture the trade‑off between missed buyers and unnecessary calls.

## Insights & Business Impact

While the primary focus here is modeling, the analysis is oriented toward business questions such as:
- Which customer profiles (age, job type, education level) have higher car insurance purchase rates?
- How do previous campaign outcomes (`Outcome`, `prev_attempts`, `days_passed`) influence conversion?
- Are there specific contact patterns (e.g., month of contact, number of contacts) associated with higher success?

Potential business impact:
- **Smarter lead prioritization:** Focus call center effort on customer segments with the highest predicted purchase probability.
- **Campaign design:** Use feature importance from tree‑based models to inform which segments to target and when.
- **Cost reduction:** Reduce unnecessary calls by deprioritizing low‑propensity customers in the calling queue.

## Installation

1. Clone the repository:
   ```
   git clone <repository_url>
   cd <repository_name>
   ```
2. (Optional) Create and activate a virtual environment:
   ```
   python3 -m venv venv
   source venv/bin/activate
   ```
3. Install dependencies:
   ```
   pip install pandas numpy matplotlib seaborn scikit-learn xgboost jupyterlab
   ```

## Usage

### Running Locally
1. Ensure `Train_data.csv` and `Test_data.csv` are in the `data/` directory.
2. Start Jupyter Lab or Notebook:
   ```
   jupyter lab
   ```
3. Open and run the main analysis notebook step by step:
   - Either `Car_Insurance.ipynb` from the project root, or  
   - `notebooks/Car_Insurance.ipynb` if you prefer working from the dedicated notebooks folder.

### Running the (stub) prediction script

There is a minimal `src/predict.py` script stub to demonstrate a production‑style project structure:

```
python -m src.predict --input data/Test_data.csv --output prediction_results.csv
```

At the moment this file is documentation‑oriented only; you can extend it to:
- Load a serialized model (e.g. from a future `models/` directory),
- Apply the same preprocessing as in the training notebook, and
- Save predictions in the same format as `Sample_Submission.csv`.

### Running on Google Colab
1. Open `car-insurance-prediction-leader-notebook.ipynb` in Google Colab.
2. Upload the `Train_data.csv` and `Test_data.csv` files when prompted.
3. Run all cells to reproduce the analysis end-to-end.

## Notebooks

- **Car_Insurance.ipynb**: Core notebook with data preprocessing, EDA, feature engineering, modeling with multiple classifiers (`LogisticRegression`, `RandomForestClassifier`, `XGBClassifier`, etc.), and hyperparameter tuning via `GridSearchCV` and `RandomizedSearchCV`. Available both in the project root and under `notebooks/`.
- **car-insurance-prediction-leader-notebook.ipynb**: Detailed exploratory workflow and baseline modeling showing performance metrics and incremental improvements (also available in the root and under `notebooks/` once moved).

## Results

- Model predictions on the test set are saved in `prediction_results.csv`.
- Compare results with `Sample_Submission.csv` for submission formatting.

## Technologies

- Python 3.x
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- xgboost
- Jupyter Notebook / Jupyter Lab

## Directory Structure

Current layout:

```
. \
├── Car_Insurance.ipynb
├── car-insurance-prediction-leader-notebook.ipynb
├── data
│   ├── Train_data.csv
│   └── Test_data.csv
├── notebooks
│   ├── Car_Insurance.ipynb          # optional working location for notebooks
│   └── car-insurance-prediction-leader-notebook.ipynb
├── src
│   └── predict.py                   # stub prediction script for future deployment
├── Sample_Submission.csv
├── prediction_results.csv
└── README.md
```

Recommended, more resume‑ready layout (after you rely solely on the `notebooks/` folder and optionally add a `models/` directory):

```
. \
├── data
│   ├── Train_data.csv
│   └── Test_data.csv
├── notebooks
│   ├── Car_Insurance.ipynb
│   └── car-insurance-prediction-leader-notebook.ipynb
├── src
│   └── predict.py
├── models                            # (optional) serialized model artifacts
├── Sample_Submission.csv
├── prediction_results.csv
└── README.md
```

This recommended layout (separating `data/`, `notebooks/`, `src/`, and optionally `models/`) signals professional project organization and makes it easier to extend the repository with reusable Python modules and serialized model artifacts.

## Contributing

Contributions are welcome! Please fork the repository and open a pull request with your improvements.

## License

This project is provided for educational purposes. No license is specified.
